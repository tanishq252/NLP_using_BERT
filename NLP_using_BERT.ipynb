{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_using_BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUMBC19bFzsmbmeSWpggPq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanishq252/NLP_using_BERT/blob/main/NLP_using_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**NLP with BERT for sentiment Analysis**"
      ],
      "metadata": {
        "id": "g_dcANMNNFaT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we are using **ktrain** library in this model, ktrain can be referred to a wrapper for deep learning libraries like TensorFlow Keras which is going to make work of the user easy just like anything. ktrain consists of BERT(Bidirectional Encoder Representation Transformers) which has pre trained deep bidirectional transformers which can be further tuned with one additional layer for creating models which are capable to perform multiple tasks\n",
        "* You can go through the following paper to get a proper idea of BERT, link : [BERT](https://arxiv.org/pdf/1810.04805.pdf)\n",
        "\n"
      ],
      "metadata": {
        "id": "kWxDnCjs0ukH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries"
      ],
      "metadata": {
        "id": "_y80SlIeNKMk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKr7LzRuM622"
      },
      "outputs": [],
      "source": [
        "!pip install ktrain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "import tensorflow as tf\n",
        "import ktrain\n",
        "from ktrain import text"
      ],
      "metadata": {
        "id": "LjLPM8LpNazh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading IMDB dataset from stanford AI"
      ],
      "metadata": {
        "id": "9uUzeTIPPQX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# below code demonstrates how we can retrieve data from the url rather than explicitly downloading data and uploading it\n",
        "dataset = tf.keras.utils.get_file(fname = \"aclImdb_v1.tar.gz\",\n",
        "                                  origin = \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "                                  extract = True)"
      ],
      "metadata": {
        "id": "o1H9jtrRN3qm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659bce7f-3b84-48bf-d389-291ccb435107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 3s 0us/step\n",
            "84140032/84125825 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.dirname(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PnrLL3JsRAsl",
        "outputId": "bbfae98c-a601-45b6-c1a9-9fd17393e6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), 'aclImdb')"
      ],
      "metadata": {
        "id": "_CBXpneWOCAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMDB_DATADIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nGuqQIGEQpZU",
        "outputId": "5d77acba-9993-42f4-e294-1a644cd5e1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/aclImdb'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting the dataset into training and testing sets"
      ],
      "metadata": {
        "id": "myeoMxsvRodw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try not to get intimidated by seeing the below code\n",
        "# down here we have splitted the data by fetching it from the data directory\n",
        "# further we have taken the classes of our dataset later we have mentioned the names of training and testing directory\n",
        "# and at the last BERT was initialized as the preprocessing mode\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) , preproc = text.texts_from_folder(datadir = IMDB_DATADIR,\n",
        "                                                                        classes = ['pos', 'neg'],\n",
        "                                                                        maxlen = 500,\n",
        "                                                                        train_test_names = ['train', 'test'],\n",
        "                                                                        preprocess_mode = 'bert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "T48_o0ocRH67",
        "outputId": "f633a791-908a-42ea-9180-6cdd9765ecce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "detected encoding: utf-8\n",
            "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: en\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Building BERT model"
      ],
      "metadata": {
        "id": "KNCbrViy45mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# indeed this is then power of ktrain library\n",
        "# within a line of code we can build super powerful models \n",
        "model = text.text_classifier(\n",
        "    name  = 'bert',\n",
        "    train_data = (x_train, y_train),\n",
        "    preproc = preproc,\n",
        ")"
      ],
      "metadata": {
        "id": "YbkJy_QfUAsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69884d29-3e92-40e4-e110-21176a709b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 500\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# above output indicates that we are having only 2 classes and length of the dataset is 500"
      ],
      "metadata": {
        "id": "n-hsD4Ti5t_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training the BERT model"
      ],
      "metadata": {
        "id": "ElasXJ7j59n6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here an instance of learner is been created wherein just like deep learning we are suppopsed to provide the training and validation data to the instance of our learner\n",
        "# as the name signifies \"learner\" is going to learn from the provided data which will be fed to the model so as to make proper predictions\n",
        "learner = ktrain.get_learner(model = model, \n",
        "                             train_data = (x_train, y_train),\n",
        "                             val_data = (x_test, y_test), \n",
        "                             batch_size= 6)"
      ],
      "metadata": {
        "id": "I2jcRyGY59UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit_onecycle() is going to train model by using Leslie Smith's 1 cycle policy and this method can be used with any optimizer\n",
        "# it is recommended to use learning rate of value 0.002 and 1 epoch as it takes long time even for single epoch\n",
        "learner.fit_onecycle(lr = 0.00002, epochs = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXBC7Mfr77vK",
        "outputId": "f43a968f-6308-4e45-b1c0-1536fdcea82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "4052/4167 [============================>.] - ETA: 3:13 - loss: 0.2559 - accuracy: 0.8949"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# overall we get an accuracy of more tha 90% using BERT"
      ],
      "metadata": {
        "id": "DfsMdzUg9gyF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}